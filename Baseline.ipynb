{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06aabb63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:38:55.829011Z",
     "start_time": "2021-09-13T10:38:54.067995Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from parse import parse\n",
    "import pretrainedmodels\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor, Compose, Scale, Grayscale, Resize, transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb64b0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:38:55.845011Z",
     "start_time": "2021-09-13T10:38:55.830014Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyper params\n",
    "num_of_class = 102\n",
    "learning_rate = 1e-03\n",
    "batch_size = 128\n",
    "input_size = 224\n",
    "device = torch.device(\"cuda\")\n",
    "train_size = 0.7\n",
    "test_size = 0.2\n",
    "directoryAgeDB = 'AgeDB/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fa857a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:38:56.432011Z",
     "start_time": "2021-09-13T10:38:55.846013Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def imageList():\n",
    "    image_list = []\n",
    "    for i, file in enumerate(sorted(os.listdir(directoryAgeDB))):\n",
    "        file_labels = parse('{}_{person}_{age}_{gender}.jpg', file)\n",
    "\n",
    "        if file_labels is None:\n",
    "            continue\n",
    "\n",
    "        image_location = os.path.join(directoryAgeDB, file)\n",
    "        gender_to_class_id = {'m': 0, 'f': 1}\n",
    "        gender = gender_to_class_id[file_labels['gender']]\n",
    "        age = int(file_labels['age'])\n",
    "        image_list.append({\n",
    "            'image_location': image_location,\n",
    "            'age': age,\n",
    "            'gender': gender\n",
    "        })\n",
    "\n",
    "    return image_list\n",
    "\n",
    "image_list = imageList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f11337cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:38:56.448011Z",
     "start_time": "2021-09-13T10:38:56.433013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11541\n",
      "3297\n",
      "1650\n"
     ]
    }
   ],
   "source": [
    "train_len = int(len(image_list) * train_size)\n",
    "test_len = int(len(image_list) * test_size)\n",
    "validate_len = len(image_list) - (train_len + test_len)\n",
    "\n",
    "train_image_list, test_image_list, validate_image_list = torch.utils.data.random_split(\n",
    "    dataset = image_list,\n",
    "    lengths = [train_len, test_len, validate_len], \n",
    "    generator = torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(len(train_image_list))\n",
    "print(len(test_image_list))\n",
    "print(len(validate_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac96b696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:38:56.464011Z",
     "start_time": "2021-09-13T10:38:56.449013Z"
    },
    "code_folding": [
     36
    ]
   },
   "outputs": [],
   "source": [
    "class AgeDBDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image_list, device, train = True, train_transform=None, test_transform=None, **kwargs):\n",
    "        self.image_list = image_list\n",
    "        self.device = device\n",
    "        self.train = train\n",
    "        self.train_transform = train_transform\n",
    "        self.test_transform = test_transform\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "\n",
    "        if self.train:\n",
    "            for i in tqdm(range(len(image_list))):\n",
    "\n",
    "                image = Image.open(self.image_list[i]['image_location']).convert('RGB')\n",
    "                image_location = self.image_list[i]['image_location']\n",
    "                age = self.image_list[i]['age']\n",
    "                gender = self.image_list[i]['gender']\n",
    "\n",
    "                image = np.array(image)\n",
    "\n",
    "                for j in range(1):\n",
    "                    if j == 0:\n",
    "                        augmented_images = self.test_transform(image=image)['image']\n",
    "                    else:\n",
    "                        augmented_images = self.train_transform(image=image)['image']\n",
    "\n",
    "                    self.images.append(augmented_images)\n",
    "                    self.labels.append({\n",
    "                        'image_location': image_location,\n",
    "                        'age': age,\n",
    "                        'gender': gender\n",
    "                    })\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        if self.train:\n",
    "            return len(self.labels)\n",
    "        else:\n",
    "            return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        if self.train:\n",
    "            image = self.images[index]\n",
    "            labels = {\n",
    "                'image_location': self.labels[index]['image_location'],\n",
    "                'age': self.labels[index]['age'],\n",
    "                'gender': self.labels[index]['gender']\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            image = Image.open(\n",
    "                self.image_list[index]['image_location']).convert('RGB')\n",
    "            image = np.array(image)\n",
    "            image = self.test_transform(image=image)['image']\n",
    "            labels = {\n",
    "                'image_location': self.image_list[index]['image_location'],\n",
    "                'age': self.image_list[index]['age'],\n",
    "                'gender': self.image_list[index]['gender']\n",
    "            }\n",
    "\n",
    "        return image.to(self.device), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8e3f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:38:56.480011Z",
     "start_time": "2021-09-13T10:38:56.465013Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [A.Resize(input_size, input_size),\n",
    "     A.ToGray(p=1),\n",
    "     ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de83481",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:39:10.499028Z",
     "start_time": "2021-09-13T10:38:56.481013Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11541/11541 [00:14<00:00, 824.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11541\n",
      "3297\n",
      "1650\n",
      "16488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainDataset = AgeDBDataset(image_list=train_image_list,\n",
    "                            device=device,\n",
    "                            train=True,\n",
    "                            train_transform=transform,\n",
    "                            test_transform=transform)\n",
    "testDataset = AgeDBDataset(image_list=test_image_list,\n",
    "                           device=device,\n",
    "                           train=False,\n",
    "                           train_transform=transform,\n",
    "                           test_transform=transform)\n",
    "valDataset = AgeDBDataset(image_list=validate_image_list,\n",
    "                          device=device,\n",
    "                          train=False,\n",
    "                          train_transform=transform,\n",
    "                          test_transform=transform)\n",
    "print(len(trainDataset))\n",
    "print(len(testDataset))\n",
    "print(len(valDataset))\n",
    "print(len(trainDataset) + len(testDataset) + len(valDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db16a8b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:39:10.515028Z",
     "start_time": "2021-09-13T10:39:10.501031Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(testDataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "validation_loader = DataLoader(valDataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5641b0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:39:12.202028Z",
     "start_time": "2021-09-13T10:39:10.517029Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "ResNet18 = pretrainedmodels.resnet18()\n",
    "ResNet18.last_linear = nn.Linear(\n",
    "    in_features=ResNet18.last_linear.in_features, \n",
    "    out_features=num_of_class, \n",
    "    bias=False\n",
    ")\n",
    "resnetModel = ResNet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fed7d490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:39:12.217028Z",
     "start_time": "2021-09-13T10:39:12.203029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, optimizer, criterion, train_loader, valid_loader, num_of_epoch):\n",
    "    total_step = len(train_loader)\n",
    "    min_valid_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_of_epoch):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        for i, (imgs, labels) in enumerate(train_loader):\n",
    "            imgs = imgs.to(device).float()\n",
    "            labels = torch.as_tensor(labels['age']).to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        for i, (imgs, labels) in enumerate(valid_loader):\n",
    "            with torch.no_grad():\n",
    "                imgs = imgs.to(device).float()\n",
    "                labels = torch.as_tensor(labels['age']).to(device)\n",
    "            \n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        print(f\"Epoch: {epoch+1}/{num_of_epoch}, Train Loss: {train_loss/len(train_loader)},  Validation Loss: {valid_loss/len(valid_loader)}\")\n",
    "              \n",
    "        if min_valid_loss > (valid_loss/len(valid_loader)):\n",
    "            print(f'Validation Loss Decreased({min_valid_loss} ---> {valid_loss/len(valid_loader)})')\n",
    "            min_valid_loss = valid_loss/len(valid_loader)\n",
    "            torch.save(resnetModel.state_dict(), 'baseline.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca9b2a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:39:12.233029Z",
     "start_time": "2021-09-13T10:39:12.218030Z"
    }
   },
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnetModel.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed4bb3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:43:01.164492Z",
     "start_time": "2021-09-13T10:39:12.234029Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Train Loss: 4.034296502123822,  Validation Loss: 3.9123041446392355\n",
      "Validation Loss Decreased(inf ---> 3.9123041446392355)\n",
      "Epoch: 2/10, Train Loss: 3.7345708254929426,  Validation Loss: 3.7281540540548472\n",
      "Validation Loss Decreased(3.9123041446392355 ---> 3.7281540540548472)\n",
      "Epoch: 3/10, Train Loss: 3.55403302528046,  Validation Loss: 3.73976940375108\n",
      "Epoch: 4/10, Train Loss: 3.38581145464719,  Validation Loss: 3.7298734738276553\n",
      "Epoch: 5/10, Train Loss: 3.2058243227529,  Validation Loss: 3.811650587962224\n",
      "Epoch: 6/10, Train Loss: 2.8842546127654693,  Validation Loss: 4.032128664163443\n",
      "Epoch: 7/10, Train Loss: 2.373264823641096,  Validation Loss: 4.358334174522986\n",
      "Epoch: 8/10, Train Loss: 1.5351285541450583,  Validation Loss: 4.918973409212553\n",
      "Epoch: 9/10, Train Loss: 0.684457887332518,  Validation Loss: 5.381367573371301\n",
      "Epoch: 10/10, Train Loss: 0.1982329669562015,  Validation Loss: 5.636270523071289\n"
     ]
    }
   ],
   "source": [
    "train(resnetModel, optimizer, criteria, train_loader, validation_loader, num_of_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a9f52dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:43:01.180495Z",
     "start_time": "2021-09-13T10:43:01.165492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def eval(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        error = torch.zeros(0).to(device)\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device).float()\n",
    "            labels = torch.as_tensor(labels['age']).to(device)\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "\n",
    "            error = torch.cat([error, torch.abs(\n",
    "                torch.subtract(torch.reshape(labels, (-1,)), torch.reshape(pred, (-1,)))\n",
    "            )])\n",
    "                        \n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            \n",
    "    #print(f\"Accuracy: {(100*correct)/total}%\")\n",
    "    print(f\"Mean Absolute Error: {(torch.mean(error))}\")\n",
    "    print(f\"Minimum: {torch.min(error)}, Maximum: {torch.max(error)}, Median: {torch.median(error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b735ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:43:15.047493Z",
     "start_time": "2021-09-13T10:43:01.181493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 7.84076452255249\n",
      "Minimum: 0.0, Maximum: 53.0, Median: 6.0\n",
      "Mean Absolute Error: 0.054934579879045486\n",
      "Minimum: 0.0, Maximum: 36.0, Median: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(resnetModel, test_loader)\n",
    "eval(resnetModel, train_loader)\n",
    "resnetModel.load_state_dict(torch.load('baseline.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d5fe78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T10:43:28.094499Z",
     "start_time": "2021-09-13T10:43:15.048494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 7.791628837585449\n",
      "Minimum: 0.0, Maximum: 50.0, Median: 6.0\n",
      "Mean Absolute Error: 6.979377746582031\n",
      "Minimum: 0.0, Maximum: 51.0, Median: 6.0\n"
     ]
    }
   ],
   "source": [
    "eval(resnetModel, test_loader)\n",
    "eval(resnetModel, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603ca8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
