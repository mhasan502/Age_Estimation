{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06aabb63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:04.462950Z",
     "start_time": "2021-09-06T04:55:03.407951Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from parse import parse\n",
    "from autocrop import Cropper\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Scale, Grayscale, Resize, transforms\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from custom_loader import AgeDBDataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb64b0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:04.478950Z",
     "start_time": "2021-09-06T04:55:04.463952Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyper params\n",
    "num_of_class = 102\n",
    "hidden_unit = 256\n",
    "learning_rate = 1e-04\n",
    "batch_size = 64\n",
    "input_size = 64\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277b6da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:04.494949Z",
     "start_time": "2021-09-06T04:55:04.479952Z"
    }
   },
   "outputs": [],
   "source": [
    "transformA = A.Compose([\n",
    "    A.Resize(input_size, input_size),\n",
    "    A.ToGray(p=1),\n",
    "    A.Rotate(limit=10, p=0.3),\n",
    "    A.HorizontalFlip(p=0.4),\n",
    "    A.OpticalDistortion(p=0.2),\n",
    "    A.augmentations.transforms.ChannelDropout(p=1.0),\n",
    "    A.OneOf([\n",
    "        A.Blur(blur_limit=3, p=0.2),\n",
    "        A.ColorJitter(p=0.2),\n",
    "    ], p=0.2),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e2a987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:04.510949Z",
     "start_time": "2021-09-06T04:55:04.495952Z"
    }
   },
   "outputs": [],
   "source": [
    "### --- AgeDB Dataset Class --- ###           {}_{person}_{age}_{gender}.jpg\n",
    "\n",
    "\n",
    "class AgeDBDataset(Dataset):\n",
    "\n",
    "    ## data loading\n",
    "    def __init__(self, directory, device, transform=None, **kwargs):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "\n",
    "        gender_to_class_id = {'m': 0, 'f': 1}\n",
    "\n",
    "        for i, file in enumerate(sorted(os.listdir(self.directory))):\n",
    "            file_labels = parse('{}_{}_{age}_{gender}.jpg', file)\n",
    "\n",
    "            if file_labels is None:\n",
    "                continue\n",
    "\n",
    "            image = Image.open(os.path.join(self.directory,\n",
    "                                            file)).convert('RGB')\n",
    "\n",
    "            ########\n",
    "            cropper = Cropper()\n",
    "\n",
    "            try:\n",
    "                #Get a Numpy array of the cropped image\n",
    "                cropped_array = cropper.crop(image)\n",
    "                #Save the cropped image with PIL\n",
    "                image = Image.fromarray(cropped_array)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            image = np.array(image)\n",
    "\n",
    "            augmented_images = self.transform(image=image)['image']\n",
    "            self.images.append(augmented_images)\n",
    "                ########\n",
    "            gender = gender_to_class_id[file_labels['gender']]\n",
    "            age = int(file_labels['age'])\n",
    "            self.labels.append({\n",
    "                'age': age,\n",
    "                'gender': gender\n",
    "            })\n",
    "\n",
    "## len(dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "## dataset[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        image = self.images[index]\n",
    "\n",
    "        labels = {\n",
    "            'age': self.labels[index]['age'],\n",
    "            'gender': self.labels[index]['gender']\n",
    "        }\n",
    "\n",
    "        return image.to(self.device), labels\n",
    "\n",
    "\n",
    "## DataLoaders - train, validate, test\n",
    "\n",
    "    def get_loaders(self, batch_size, train_size, test_size, random_seed,\n",
    "                    **kwargs):\n",
    "        train_len = int(len(self) * train_size)\n",
    "        test_len = int(len(self) * test_size)\n",
    "        validate_len = len(self) - (train_len + test_len)\n",
    "\n",
    "        self.trainDataset, self.validateDataset, self.testDataset = torch.utils.data.random_split(\n",
    "            dataset=self,\n",
    "            lengths=[train_len, validate_len, test_len],\n",
    "            generator=torch.Generator().manual_seed(random_seed))\n",
    "\n",
    "        train_loader = DataLoader(self.trainDataset, batch_size=batch_size)\n",
    "        validate_loader = DataLoader(self.validateDataset,\n",
    "                                     batch_size=batch_size)\n",
    "        test_loader = DataLoader(self.testDataset, batch_size=batch_size)\n",
    "\n",
    "        return train_loader, validate_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de83481",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:20.293950Z",
     "start_time": "2021-09-06T04:55:04.511952Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = AgeDBDataset(\n",
    "    directory='AgeDB/',\n",
    "    transform=transformA,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64cc1bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:20.309950Z",
     "start_time": "2021-09-06T04:55:20.294951Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set, validation_set, test_set = dataset.get_loaders(\n",
    "    batch_size=batch_size,\n",
    "    train_size=0.8,\n",
    "    test_size=0.2,\n",
    "    random_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f3a0e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:20.324951Z",
     "start_time": "2021-09-06T04:55:20.312950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16488"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5641b0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:20.339951Z",
     "start_time": "2021-09-06T04:55:20.326954Z"
    }
   },
   "outputs": [],
   "source": [
    "class AgeDBConvModel(nn.Module):\n",
    "    def __init__(self, num_of_classes):\n",
    "        super(AgeDBConvModel, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=2), #(64+2(2)-3)+1=66\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #((66-2)/2)+1 = 33\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=2), #(33+2(2)-3)+1=35\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #((35-2)/2)+1 = 17 + 0.5\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=2), #(17+2(2)-3)+1=19\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #((19-2)/2)+1 = 9 + 0.5\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=2), #(9+2(2)-3)+1=11\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #((11-2)/2)+1 = 5 + 0.5\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=2), #(5+2(2)-3)+1=7\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #((7-2)/2)+1 = 3 + 0.5\n",
    "        )\n",
    "        self.fc1 = nn.Linear(3*3*512, num_of_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e2304a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:20.545951Z",
     "start_time": "2021-09-06T04:55:20.341953Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from kornia.losses import FocalLoss as focal_loss\n",
    "def label_smoothing_criterion(alpha=0.1, distribution='uniform', std=0.5, reduction='mean'):\n",
    "    def _label_smoothing_criterion(logits, labels):\n",
    "        n_classes = logits.size(1)\n",
    "        device = logits.device\n",
    "        # manipulate labels\n",
    "        one_hot = one_hot_encoding(labels, n_classes).float().to(device)\n",
    "        if distribution == 'uniform':\n",
    "            uniform = torch.ones_like(one_hot).to(device)/n_classes\n",
    "            soft_labels = (1 - alpha)*one_hot + alpha*uniform\n",
    "        elif distribution == 'gaussian':\n",
    "            dist = get_gaussian_label_distribution(n_classes, std=std)\n",
    "            soft_labels = torch.from_numpy(dist[labels.cpu().numpy()]).to(device)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        loss = cross_entropy_loss_one_hot(logits, soft_labels.float(), reduction)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return _label_smoothing_criterion\n",
    "\n",
    "def cost_sensitive_loss(input, target, M):\n",
    "    if input.size(0) != target.size(0):\n",
    "        raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n",
    "                         .format(input.size(0), target.size(0)))\n",
    "    device = input.device\n",
    "    M = M.to(device)\n",
    "    return (M[target, :]*input.float()).sum(axis=-1)\n",
    "    # return torch.diag(torch.matmul(input, M[:, target]))\n",
    "\n",
    "class CostSensitiveRegularizedLoss(nn.Module):\n",
    "    def __init__(self,  n_classes=5, exp=2, normalization='softmax', reduction='mean', base_loss='ce', lambd=10):\n",
    "        super(CostSensitiveRegularizedLoss, self).__init__()\n",
    "        if normalization == 'softmax':\n",
    "            self.normalization = nn.Softmax(dim=1)\n",
    "        elif normalization == 'sigmoid':\n",
    "            self.normalization = nn.Sigmoid()\n",
    "        else:\n",
    "            self.normalization = None\n",
    "        self.reduction = reduction\n",
    "        x = np.abs(np.arange(n_classes, dtype=np.float32))\n",
    "        M = np.abs((x[:, np.newaxis] - x[np.newaxis, :])) ** exp\n",
    "        #\n",
    "        # M_oph = np.array([\n",
    "        #                 [1469, 4, 5,  0,  0],\n",
    "        #                 [58, 62,  5,  0,  0],\n",
    "        #                 [22, 3, 118,  1,  0],\n",
    "        #                 [0, 0,   13, 36,  1],\n",
    "        #                 [0, 0,    0,  1, 15]\n",
    "        #                 ], dtype=np.float)\n",
    "        # M_oph = M_oph.T\n",
    "        # # Normalize M_oph to obtain M_difficulty:\n",
    "        # M_difficulty = 1-np.divide(M_oph, np.sum(M_oph, axis=1)[:, None])\n",
    "        # # OPTION 1: average M and M_difficulty:\n",
    "        # M = 0.5 * M + 0.5 * M_difficulty\n",
    "        # ################\n",
    "        # # OPTION 2: replace uninformative entries in M_difficulty by entries of M:\n",
    "        # # M_difficulty[M_oph == 0] = M[M_oph == 0]\n",
    "        # # M = M_difficulty\n",
    "\n",
    "        M /= M.max()\n",
    "        self.M = torch.from_numpy(M)\n",
    "        self.lambd = lambd\n",
    "        self.base_loss = base_loss\n",
    "\n",
    "        if self.base_loss == 'ce':\n",
    "            self.base_loss = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "        elif self.base_loss == 'ls':\n",
    "            self.base_loss = label_smoothing_criterion(distribution='uniform', reduction=reduction)\n",
    "        elif self.base_loss == 'gls':\n",
    "            self.base_loss = label_smoothing_criterion(distribution='gaussian', reduction=reduction)\n",
    "        elif self.base_loss == 'focal_loss':\n",
    "            kwargs = {\"alpha\": 0.5, \"gamma\": 2.0, \"reduction\": reduction}\n",
    "            self.base_loss = focal_loss(**kwargs)\n",
    "        else:\n",
    "            sys.exit('not a supported base_loss')\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        base_l = self.base_loss(logits, target)\n",
    "        if self.lambd == 0:\n",
    "            return self.base_loss(logits, target)\n",
    "        else:\n",
    "            preds = self.normalization(logits)\n",
    "            loss = cost_sensitive_loss(preds, target, self.M)\n",
    "            if self.reduction == 'none':\n",
    "                return base_l + self.lambd*loss\n",
    "            elif self.reduction == 'mean':\n",
    "                return base_l + self.lambd*loss.mean()\n",
    "            elif self.reduction == 'sum':\n",
    "                return base_l + self.lambd*loss.sum()\n",
    "            else:\n",
    "                raise ValueError('`reduction` must be one of \\'none\\', \\'mean\\', or \\'sum\\'.')\n",
    "\n",
    "def get_cost_sensitive_criterion(n_classes=5, exp=2):\n",
    "    train_criterion = CostSensitiveLoss(n_classes, exp=exp, normalization='softmax')\n",
    "    val_criterion = CostSensitiveLoss(n_classes, exp=exp, normalization='softmax')\n",
    "    return train_criterion, val_criterion\n",
    "\n",
    "def get_cost_sensitive_regularized_criterion(base_loss='ce', n_classes=5, lambd=1, exp=2):\n",
    "    train_criterion = CostSensitiveRegularizedLoss(n_classes, exp=exp, normalization='softmax', base_loss=base_loss, lambd=lambd)\n",
    "    val_criterion = CostSensitiveRegularizedLoss(n_classes, exp=exp, normalization='softmax', base_loss=base_loss, lambd=lambd)\n",
    "\n",
    "    return train_criterion, val_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6938c26a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:22.489950Z",
     "start_time": "2021-09-06T04:55:20.547952Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "convModel = AgeDBConvModel(num_of_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed7d490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:22.505950Z",
     "start_time": "2021-09-06T04:55:22.490951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "def train(model, optimizer, criterion, train_loader, num_of_epoch):\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_of_epoch):\n",
    "        for i, (imgs, labels) in enumerate(train_loader):\n",
    "            imgs = imgs.to(device).float()\n",
    "            labels = torch.as_tensor(labels['age']).to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1)%total_step == 0:\n",
    "                print(f\"Epoch: {epoch+1}/{num_of_epoch}, Step: {i+1}/{total_step}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca9b2a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:22.520950Z",
     "start_time": "2021-09-06T04:55:22.506950Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "criteria = CostSensitiveRegularizedLoss(n_classes=num_of_class, base_loss='focal_loss', reduction='sum') \n",
    "optimizer = torch.optim.Adam(convModel.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed4bb3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:57:41.895950Z",
     "start_time": "2021-09-06T04:55:22.521951Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, Step: 207/207, Loss: 12.115411758422852\n",
      "Epoch: 2/20, Step: 207/207, Loss: 11.964411735534668\n",
      "Epoch: 3/20, Step: 207/207, Loss: 11.605792999267578\n",
      "Epoch: 4/20, Step: 207/207, Loss: 11.180627822875977\n",
      "Epoch: 5/20, Step: 207/207, Loss: 9.91624927520752\n",
      "Epoch: 6/20, Step: 207/207, Loss: 8.220314025878906\n",
      "Epoch: 7/20, Step: 207/207, Loss: 6.26442813873291\n",
      "Epoch: 8/20, Step: 207/207, Loss: 4.426490783691406\n",
      "Epoch: 9/20, Step: 207/207, Loss: 2.760051727294922\n",
      "Epoch: 10/20, Step: 207/207, Loss: 2.126011371612549\n",
      "Epoch: 11/20, Step: 207/207, Loss: 1.7183563709259033\n",
      "Epoch: 12/20, Step: 207/207, Loss: 1.0723979473114014\n",
      "Epoch: 13/20, Step: 207/207, Loss: 1.1674399375915527\n",
      "Epoch: 14/20, Step: 207/207, Loss: 1.6420009136199951\n",
      "Epoch: 15/20, Step: 207/207, Loss: 0.7914124727249146\n",
      "Epoch: 16/20, Step: 207/207, Loss: 0.237967848777771\n",
      "Epoch: 17/20, Step: 207/207, Loss: 0.2801882028579712\n",
      "Epoch: 18/20, Step: 207/207, Loss: 0.29306694865226746\n",
      "Epoch: 19/20, Step: 207/207, Loss: 0.17547188699245453\n",
      "Epoch: 20/20, Step: 207/207, Loss: 0.13627511262893677\n"
     ]
    }
   ],
   "source": [
    "train(convModel, optimizer, criteria, train_set, num_of_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e42f1efb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:57:41.911951Z",
     "start_time": "2021-09-06T04:57:41.896952Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "def eval(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        error = torch.zeros(0).to(device)\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device).float()\n",
    "            labels = torch.as_tensor(labels['age']).to(device)\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "\n",
    "            error = torch.cat([error, torch.abs(\n",
    "                torch.subtract(torch.reshape(labels, (-1,)), torch.reshape(pred, (-1,)))\n",
    "            )])\n",
    "                        \n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            \n",
    "    print(f\"Accuracy: {(100*correct)/total}%\")\n",
    "    print(f\"Mean Absolute Error: {(torch.mean(error))}\")\n",
    "    print(f\"Minimum: {torch.min(error)}, Maximum: {torch.max(error)}, Median: {torch.median(error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10b735ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:57:42.279949Z",
     "start_time": "2021-09-06T04:57:41.912950Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 2.8814073400060662%\n",
      "Mean Absolute Error: 12.0594482421875\n",
      "Minimum: 0.0, Maximum: 63.0, Median: 10.0\n"
     ]
    }
   ],
   "source": [
    "eval(convModel, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96d5fe78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:57:43.639949Z",
     "start_time": "2021-09-06T04:57:42.280952Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.7338893100834%\n",
      "Mean Absolute Error: 0.14874905347824097\n",
      "Minimum: 0.0, Maximum: 48.0, Median: 0.0\n"
     ]
    }
   ],
   "source": [
    "eval(convModel, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156e1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
