{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06aabb63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:01.455951Z",
     "start_time": "2021-09-06T04:55:00.436953Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from parse import parse\n",
    "from autocrop import Cropper\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Scale, Grayscale, Resize, transforms\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from custom_loader import AgeDBDataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb64b0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:01.471950Z",
     "start_time": "2021-09-06T04:55:01.457950Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyper params\n",
    "num_of_class = 102\n",
    "hidden_unit = 256\n",
    "learning_rate = 1e-04\n",
    "batch_size = 64\n",
    "input_size = 64\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277b6da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:01.487950Z",
     "start_time": "2021-09-06T04:55:01.472951Z"
    }
   },
   "outputs": [],
   "source": [
    "transformA = A.Compose([\n",
    "    A.Resize(input_size, input_size),\n",
    "    A.ToGray(p=1),\n",
    "    A.Rotate(limit=10, p=0.3),\n",
    "    A.HorizontalFlip(p=0.4),\n",
    "    A.OpticalDistortion(p=0.2),\n",
    "    A.augmentations.transforms.ChannelDropout(p=1.0),\n",
    "    A.OneOf([\n",
    "        A.Blur(blur_limit=3, p=0.2),\n",
    "        A.ColorJitter(p=0.2),\n",
    "    ], p=0.2),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e2a987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:01.502950Z",
     "start_time": "2021-09-06T04:55:01.488951Z"
    }
   },
   "outputs": [],
   "source": [
    "### --- AgeDB Dataset Class --- ###           {}_{person}_{age}_{gender}.jpg\n",
    "\n",
    "\n",
    "class AgeDBDataset(Dataset):\n",
    "\n",
    "    ## data loading\n",
    "    def __init__(self, directory, device, transform=None, **kwargs):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "\n",
    "        gender_to_class_id = {'m': 0, 'f': 1}\n",
    "\n",
    "        for i, file in enumerate(sorted(os.listdir(self.directory))):\n",
    "            file_labels = parse('{}_{}_{age}_{gender}.jpg', file)\n",
    "\n",
    "            if file_labels is None:\n",
    "                continue\n",
    "\n",
    "            image = Image.open(os.path.join(self.directory,\n",
    "                                            file)).convert('RGB')\n",
    "\n",
    "            ########\n",
    "            cropper = Cropper()\n",
    "\n",
    "            try:\n",
    "                #Get a Numpy array of the cropped image\n",
    "                cropped_array = cropper.crop(image)\n",
    "                #Save the cropped image with PIL\n",
    "                image = Image.fromarray(cropped_array)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            image = np.array(image)\n",
    "\n",
    "            augmented_images = self.transform(image=image)['image']\n",
    "            self.images.append(augmented_images)\n",
    "                ########\n",
    "            gender = gender_to_class_id[file_labels['gender']]\n",
    "            age = int(file_labels['age'])\n",
    "            self.labels.append({\n",
    "                'age': age,\n",
    "                'gender': gender\n",
    "            })\n",
    "\n",
    "## len(dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "## dataset[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        image = self.images[index]\n",
    "\n",
    "        labels = {\n",
    "            'age': self.labels[index]['age'],\n",
    "            'gender': self.labels[index]['gender']\n",
    "        }\n",
    "\n",
    "        return image.to(self.device), labels\n",
    "\n",
    "\n",
    "## DataLoaders - train, validate, test\n",
    "\n",
    "    def get_loaders(self, batch_size, train_size, test_size, random_seed,\n",
    "                    **kwargs):\n",
    "        train_len = int(len(self) * train_size)\n",
    "        test_len = int(len(self) * test_size)\n",
    "        validate_len = len(self) - (train_len + test_len)\n",
    "\n",
    "        self.trainDataset, self.validateDataset, self.testDataset = torch.utils.data.random_split(\n",
    "            dataset=self,\n",
    "            lengths=[train_len, validate_len, test_len],\n",
    "            generator=torch.Generator().manual_seed(random_seed))\n",
    "\n",
    "        train_loader = DataLoader(self.trainDataset, batch_size=batch_size)\n",
    "        validate_loader = DataLoader(self.validateDataset,\n",
    "                                     batch_size=batch_size)\n",
    "        test_loader = DataLoader(self.testDataset, batch_size=batch_size)\n",
    "\n",
    "        return train_loader, validate_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de83481",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:17.139953Z",
     "start_time": "2021-09-06T04:55:01.504951Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = AgeDBDataset(\n",
    "    directory='AgeDB/',\n",
    "    transform=transformA,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64cc1bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:17.154951Z",
     "start_time": "2021-09-06T04:55:17.140951Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set, validation_set, test_set = dataset.get_loaders(\n",
    "    batch_size=batch_size,\n",
    "    train_size=0.8,\n",
    "    test_size=0.2,\n",
    "    random_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f3a0e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:17.169951Z",
     "start_time": "2021-09-06T04:55:17.156951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16488"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5641b0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:17.185955Z",
     "start_time": "2021-09-06T04:55:17.170952Z"
    }
   },
   "outputs": [],
   "source": [
    "class AgeDBConvModel(nn.Module):\n",
    "    def __init__(self, num_of_classes):\n",
    "        super(AgeDBConvModel, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=2), #(64+2(2)-3)+1=66\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #((66-2)/2)+1 = 33\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=2), #(33+2(2)-3)+1=35\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #((35-2)/2)+1 = 17 + 0.5\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=2), #(17+2(2)-3)+1=19\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #((19-2)/2)+1 = 9 + 0.5\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=2), #(9+2(2)-3)+1=11\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #((11-2)/2)+1 = 5 + 0.5\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=2), #(5+2(2)-3)+1=7\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #((7-2)/2)+1 = 3 + 0.5\n",
    "        )\n",
    "        self.fc1 = nn.Linear(3*3*512, num_of_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "560bd428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:17.343952Z",
     "start_time": "2021-09-06T04:55:17.186950Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "from kornia.losses import FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6938c26a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:18.871953Z",
     "start_time": "2021-09-06T04:55:17.344951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "convModel = AgeDBConvModel(num_of_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed7d490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:18.887951Z",
     "start_time": "2021-09-06T04:55:18.872951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "def train(model, optimizer, criterion, train_loader, num_of_epoch):\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_of_epoch):\n",
    "        for i, (imgs, labels) in enumerate(train_loader):\n",
    "            imgs = imgs.to(device).float()\n",
    "            labels = torch.as_tensor(labels['age']).to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1)%total_step == 0:\n",
    "                print(f\"Epoch: {epoch+1}/{num_of_epoch}, Step: {i+1}/{total_step}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca9b2a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:55:18.903950Z",
     "start_time": "2021-09-06T04:55:18.888951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "criteria = FocalLoss(alpha=0.5, gamma=2.0, reduction='mean') \n",
    "optimizer = torch.optim.Adam(convModel.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed4bb3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:57:35.140949Z",
     "start_time": "2021-09-06T04:55:18.904951Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, Step: 207/207, Loss: 1.8928711414337158\n",
      "Epoch: 2/20, Step: 207/207, Loss: 1.3358629941940308\n",
      "Epoch: 3/20, Step: 207/207, Loss: 0.6305738687515259\n",
      "Epoch: 4/20, Step: 207/207, Loss: 0.15026478469371796\n",
      "Epoch: 5/20, Step: 207/207, Loss: 0.03131726384162903\n",
      "Epoch: 6/20, Step: 207/207, Loss: 0.01751764863729477\n",
      "Epoch: 7/20, Step: 207/207, Loss: 0.013268990442156792\n",
      "Epoch: 8/20, Step: 207/207, Loss: 0.012306386604905128\n",
      "Epoch: 9/20, Step: 207/207, Loss: 0.01674063131213188\n",
      "Epoch: 10/20, Step: 207/207, Loss: 0.013223685324192047\n",
      "Epoch: 11/20, Step: 207/207, Loss: 0.006175786256790161\n",
      "Epoch: 12/20, Step: 207/207, Loss: 0.003642220748588443\n",
      "Epoch: 13/20, Step: 207/207, Loss: 0.009154293686151505\n",
      "Epoch: 14/20, Step: 207/207, Loss: 0.00581746082752943\n",
      "Epoch: 15/20, Step: 207/207, Loss: 0.004658739548176527\n",
      "Epoch: 16/20, Step: 207/207, Loss: 0.0028450523968786\n",
      "Epoch: 17/20, Step: 207/207, Loss: 0.004140210337936878\n",
      "Epoch: 18/20, Step: 207/207, Loss: 0.001958843320608139\n",
      "Epoch: 19/20, Step: 207/207, Loss: 0.0013004353968426585\n",
      "Epoch: 20/20, Step: 207/207, Loss: 0.0009391360799781978\n"
     ]
    }
   ],
   "source": [
    "train(convModel, optimizer, criteria, train_set, num_of_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e42f1efb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:57:35.156949Z",
     "start_time": "2021-09-06T04:57:35.141951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "def eval(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        error = torch.zeros(0).to(device)\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device).float()\n",
    "            labels = torch.as_tensor(labels['age']).to(device)\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "\n",
    "            error = torch.cat([error, torch.abs(\n",
    "                torch.subtract(torch.reshape(labels, (-1,)), torch.reshape(pred, (-1,)))\n",
    "            )])\n",
    "                        \n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            \n",
    "    print(f\"Accuracy: {(100*correct)/total}%\")\n",
    "    print(f\"Mean Absolute Error: {(torch.mean(error))}\")\n",
    "    print(f\"Minimum: {torch.min(error)}, Maximum: {torch.max(error)}, Median: {torch.median(error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10b735ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:57:36.312952Z",
     "start_time": "2021-09-06T04:57:35.158951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 3.1847133757961785%\n",
      "Mean Absolute Error: 13.693964004516602\n",
      "Minimum: 0.0, Maximum: 68.0, Median: 11.0\n"
     ]
    }
   ],
   "source": [
    "eval(convModel, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96d5fe78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:57:40.531950Z",
     "start_time": "2021-09-06T04:57:36.313952Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.12964366944655%\n",
      "Mean Absolute Error: 1.2520849704742432\n",
      "Minimum: 0.0, Maximum: 61.0, Median: 0.0\n"
     ]
    }
   ],
   "source": [
    "eval(convModel, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156e1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
